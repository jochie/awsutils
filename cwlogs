#!/usr/bin/env python3
# -*- mode: python; tab-width: 4; indent-tabs-mode: nil -*- for emacs

import argparse
import re
import sys
from time import ctime
import boto3


def parse_options():
    parser = argparse.ArgumentParser(
        description='Browsing CloudWatch Logs'
    )
    # Generic (AWS) options
    parser.add_argument('-v', '--verbose',
                        help="Enable verbose output",
                        default=False,
                        action='store_true')
    parser.add_argument('-n', '--dryrun',
                        help="Request dryrun (noop) mode",
                        default=False,
                        action='store_true')
    parser.add_argument('-r', '--region',
                        help="Provide a non-default AWS region")
    parser.add_argument('-p', '--profile',
                        help="Provide a non-default AWS profile")

    # Command-specific options:
    parser.add_argument('-d', '--debug',
                        help="Enable debug output",
                        default=0, type=int)
    parser.add_argument('-l', '--list',
                        help="List the available Log Groups",
                        default=False,
                        action='store_true')
    parser.add_argument('-t', '--tail',
                        help="Show the last few events of a specific Log Group")
    parser.add_argument('-e', '--events',
                        help="Limit the number of events per log group",
                        default=10, type=int)
    parser.add_argument('--noise',
                        help="Suppress noisy events (typically from Lambdas)",
                        default=False,
                        action='store_true')
    parser.add_argument('--group',
                        help="Group the events by date/time.",
                        default=False,
                        action='store_true')
    parser.add_argument('--grep',
                        help="Show only the groups or events that match the provided pattern.")
    parser.add_argument('--reverse',
                        help="Traverse the logs explicitly in reverse (appears to be sub-optimal)",
                        action='store_true')
    opts = parser.parse_args()

    # Any post-processing, like checking mutually exclusive options, mandatory
    # options, happens here.

    if opts.list and opts.tail:
        print("The options --list and --group are mutually exclusive. Pick one!")
        sys.exit(1)

    return opts


def fetch_log_events(logs, opts, stream, limit):
    queries = 0
    lines = []
    events = 0
    token = None
    while True:
        next_token = {}
        if token:
            next_token['nextToken'] = token
        if opts.debug > 1:
            print(f"logs.get_log_events(logGroupName={opts.tail}, logStreamName={stream}, startFromHead={not opts.reverse}, {next_token})")
        queries += 1
        event_response = logs.get_log_events(
            logGroupName=opts.tail,
            logStreamName=stream,
            startFromHead=not opts.reverse,
            **next_token)
        if 'events' not in event_response:
            # Be sure to return what we already collected, if anything.
            lines.reverse()
            return events, lines, queries
        if opts.debug > 2:
            print(f"  Returned {event_response}")
        event_list = event_response['events']
        if opts.reverse:
            event_list.reverse()
        for event in event_list:
            msg = event['message'].rstrip()
            if opts.noise:
                m = re.match(r"^(INIT_START |START RequestId: |END RequestId: |REPORT RequestId: )", msg)
                if m:
                    continue

            if opts.grep:
                m = re.match(opts.grep, msg)
                if not m:
                    continue

            events += 1
            timestamp = int(int(event['timestamp'])/1000)
            lines.append([timestamp, msg])
            if opts.reverse and events >= limit:
                # Reached the limit
                return events, lines, queries

        tokenName = 'nextBackwardToken' if opts.reverse else 'nextForwardToken'
        if tokenName not in event_response:
            break
        if not token:
            token = event_response[tokenName]
        else:
            # From https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/logs/client/get_log_events.html
            # If you have reached the end of the stream, it returns the same token you passed in.
            if token == event_response[tokenName]:
                break
            token = event_response[tokenName]

    if not opts.reverse:
        # print(f"Lines:\n{lines}")
        lines.reverse()
        if events > limit:
            # Reached the limit
            if opts.debug > 0:
                print(f"  Truncating lines to {limit} out of {events} entries.")
            return limit, lines[:limit], queries

    return events, lines, queries


def fetch_log_streams(logs, opts):
    lines = []
    limit = opts.events
    token = {}
    queries = 0
    while True:
        if opts.debug > 1:
            print(f"logs.describe_log_streams(logGroupName={opts.tail}, orderBy='LastEventTime', descending=True, {token}")
        queries += 1
        stream_response = logs.describe_log_streams(
            logGroupName=opts.tail,
            orderBy='LastEventTime',
            descending=True,
            **token)
        if 'logStreams' not in stream_response:
            return lines, queries

        for log_stream in stream_response['logStreams']:
            entries, newlines, event_queries = fetch_log_events(logs, opts, log_stream['logStreamName'], limit)
            lines = lines + newlines
            queries += event_queries
            if opts.debug > 0:
                print(f"fetch_log_events() returned {entries} new events.")
            limit -= entries
            if limit <= 0:
                return lines, queries

        if 'nextToken' not in stream_response:
            break
        token = { 'nextToken': stream_response['nextToken'] }
    return lines, queries


def list_log_groups(logs, opts):
    response = logs.describe_log_groups()
    if 'logGroups' not in response:
        print("No Log Groups found for this profile/region.")
        return
    for log_group in response['logGroups']:
        if opts.grep:
            m = re.match(opts.grep, log_group['logGroupName'])
            if not m:
                continue
        print(f"{log_group['logGroupName']} (Created: {ctime(int(log_group['creationTime']) / 1000)}; Retention: {log_group['retentionInDays']} days; Storage: {log_group['storedBytes']} bytes)")
    return


def fetch_log_group(logs, opts):
    # Is logGroupNamePattern a recent addition?
    response = logs.describe_log_groups(
        logGroupNamePrefix=opts.tail
    )
    if 'logGroups' not in response:
        print("No such Log Group found for this profile/region.")
        return

    for log_group in response['logGroups']:
        if log_group['logGroupName'] != opts.tail:
            # I used logGroupNamePrefix but only want an exact match. Did I
            # miss some better call that I can make instead?
            continue

        lines, queries = fetch_log_streams(logs, opts)
        last_timestamp = None
        for entry in reversed(lines):
            timestamp = entry[0]
            msg = entry[1]
            if opts.group:
                prefix = "    "
                if not last_timestamp or timestamp != last_timestamp:
                    print(f"{ctime(timestamp)}:")
                    last_timestamp = timestamp
            else:
                prefix = f"{ctime(timestamp)}: "
            for line in msg.split("\n"):
                print(f"{prefix}{line}")
        if opts.debug > 0:
            print(f"API queries sent: {queries}")
    return


def fetch_log_groups(logs, opts):
    if not opts.tail:
        list_log_groups(logs, opts)
        return
    fetch_log_group(logs, opts)
    return


def main():
    opts = parse_options()
    if opts.profile:
        if opts.region:
            session = boto3.session.Session(profile_name=opts.profile,
                                            region_name=opts.region)
        else:
            session = boto3.session.Session(profile_name=opts.profile)
    else:
        if opts.region:
            session = boto3.session.Session(region_name=opts.region)
        else:
            session = boto3.session.Session()
    logs = session.client('logs')

    fetch_log_groups(logs, opts)
    return

if __name__ == "__main__":
    main()
